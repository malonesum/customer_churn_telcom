== Teleco Customer Churn Analysis

=== Dataset from https://github.com/irinhwng/Consumer-Insights-Metrics_and_Predictions

== Importing Dataset for Data Cleaning


+*In[496]:*+
[source, ipython3]
----
import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('~/Desktop/Final_Project_UCLA/telco_kaggle.csv')
df2 = pd.read_csv('~/Desktop/Final_Project_UCLA/telco_kaggle.csv')
----


+*In[497]:*+
[source, ipython3]
----
#First look at the data, observing the number of columns, rows, and datatypes.
df.info()
----


+*Out[497]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7043 entries, 0 to 7042
Data columns (total 21 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   customerID        7043 non-null   object 
 1   gender            7043 non-null   object 
 2   SeniorCitizen     7043 non-null   int64  
 3   Partner           7043 non-null   object 
 4   Dependents        7043 non-null   object 
 5   tenure            7043 non-null   int64  
 6   PhoneService      7043 non-null   object 
 7   MultipleLines     7043 non-null   object 
 8   InternetService   7043 non-null   object 
 9   OnlineSecurity    7043 non-null   object 
 10  OnlineBackup      7043 non-null   object 
 11  DeviceProtection  7043 non-null   object 
 12  TechSupport       7043 non-null   object 
 13  StreamingTV       7043 non-null   object 
 14  StreamingMovies   7043 non-null   object 
 15  Contract          7043 non-null   object 
 16  PaperlessBilling  7043 non-null   object 
 17  PaymentMethod     7043 non-null   object 
 18  MonthlyCharges    7043 non-null   float64
 19  TotalCharges      7043 non-null   object 
 20  Churn             7043 non-null   object 
dtypes: float64(1), int64(2), object(18)
memory usage: 1.1+ MB
----


+*In[498]:*+
[source, ipython3]
----
#Looking to see that the count per field continues to match 7043, the fields for unique make sense, and that the
 #top entries per field also do not cause for concern. The datatypes listed above should align with column outputs
df.describe(include='all')
----


+*Out[498]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |customerID |gender |SeniorCitizen |Partner |Dependents |tenure
|PhoneService |MultipleLines |InternetService |OnlineSecurity |...
|DeviceProtection |TechSupport |StreamingTV |StreamingMovies |Contract
|PaperlessBilling |PaymentMethod |MonthlyCharges |TotalCharges |Churn
|count |7043 |7043 |7043.000000 |7043 |7043 |7043.000000 |7043 |7043
|7043 |7043 |... |7043 |7043 |7043 |7043 |7043 |7043 |7043 |7043.000000
|7043 |7043

|unique |7043 |2 |NaN |2 |2 |NaN |2 |3 |3 |3 |... |3 |3 |3 |3 |3 |2 |4
|NaN |6531 |2

|top |4208-UFFGW |Male |NaN |No |No |NaN |Yes |No |Fiber optic |No |...
|No |No |No |No |Month-to-month |Yes |Electronic check |NaN | |No

|freq |1 |3555 |NaN |3641 |4933 |NaN |6361 |3390 |3096 |3498 |... |3095
|3473 |2810 |2785 |3875 |4171 |2365 |NaN |11 |5174

|mean |NaN |NaN |0.162147 |NaN |NaN |32.371149 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |64.761692 |NaN |NaN

|std |NaN |NaN |0.368612 |NaN |NaN |24.559481 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |30.090047 |NaN |NaN

|min |NaN |NaN |0.000000 |NaN |NaN |0.000000 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |18.250000 |NaN |NaN

|25% |NaN |NaN |0.000000 |NaN |NaN |9.000000 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |35.500000 |NaN |NaN

|50% |NaN |NaN |0.000000 |NaN |NaN |29.000000 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |70.350000 |NaN |NaN

|75% |NaN |NaN |0.000000 |NaN |NaN |55.000000 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |89.850000 |NaN |NaN

|max |NaN |NaN |1.000000 |NaN |NaN |72.000000 |NaN |NaN |NaN |NaN |...
|NaN |NaN |NaN |NaN |NaN |NaN |NaN |118.750000 |NaN |NaN
|===

11 rows × 21 columns
----

== From the output above, NaN is not unusual coming up in the mean, std, min, 25%, 50%, 75%, max for the categorical columns. However, NaN appears in the TotalCharges column, so the blanks need to be replaced with zeros. To confirm, I will dive into the TotalCharges column further.


+*In[499]:*+
[source, ipython3]
----
print(df['gender'].unique()) #This is correct, and identified as object type
print(df['TotalCharges'].unique()) #Replace blank splace with 0, as the customer has not yet paid the company
----


+*Out[499]:*+
----
['Female' 'Male']
['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']
----


+*In[500]:*+
[source, ipython3]
----
#Replaces blank spaces with 0, and redefines the data type as float
df['TotalCharges'] = df['TotalCharges'].replace(" ", 0).astype('float64')
----


+*In[501]:*+
[source, ipython3]
----
#Checking the change to column was completed -- successful
df.info()
----


+*Out[501]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7043 entries, 0 to 7042
Data columns (total 21 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   customerID        7043 non-null   object 
 1   gender            7043 non-null   object 
 2   SeniorCitizen     7043 non-null   int64  
 3   Partner           7043 non-null   object 
 4   Dependents        7043 non-null   object 
 5   tenure            7043 non-null   int64  
 6   PhoneService      7043 non-null   object 
 7   MultipleLines     7043 non-null   object 
 8   InternetService   7043 non-null   object 
 9   OnlineSecurity    7043 non-null   object 
 10  OnlineBackup      7043 non-null   object 
 11  DeviceProtection  7043 non-null   object 
 12  TechSupport       7043 non-null   object 
 13  StreamingTV       7043 non-null   object 
 14  StreamingMovies   7043 non-null   object 
 15  Contract          7043 non-null   object 
 16  PaperlessBilling  7043 non-null   object 
 17  PaymentMethod     7043 non-null   object 
 18  MonthlyCharges    7043 non-null   float64
 19  TotalCharges      7043 non-null   float64
 20  Churn             7043 non-null   object 
dtypes: float64(2), int64(2), object(17)
memory usage: 1.1+ MB
----


+*In[502]:*+
[source, ipython3]
----
df.head()
----


+*Out[502]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |customerID |gender |SeniorCitizen |Partner |Dependents |tenure
|PhoneService |MultipleLines |InternetService |OnlineSecurity |...
|DeviceProtection |TechSupport |StreamingTV |StreamingMovies |Contract
|PaperlessBilling |PaymentMethod |MonthlyCharges |TotalCharges |Churn
|0 |7590-VHVEG |Female |0 |Yes |No |1 |No |No phone service |DSL |No
|... |No |No |No |No |Month-to-month |Yes |Electronic check |29.85
|29.85 |No

|1 |5575-GNVDE |Male |0 |No |No |34 |Yes |No |DSL |Yes |... |Yes |No |No
|No |One year |No |Mailed check |56.95 |1889.50 |No

|2 |3668-QPYBK |Male |0 |No |No |2 |Yes |No |DSL |Yes |... |No |No |No
|No |Month-to-month |Yes |Mailed check |53.85 |108.15 |Yes

|3 |7795-CFOCW |Male |0 |No |No |45 |No |No phone service |DSL |Yes |...
|Yes |Yes |No |No |One year |No |Bank transfer (automatic) |42.30
|1840.75 |No

|4 |9237-HQITU |Female |0 |No |No |2 |Yes |No |Fiber optic |No |... |No
|No |No |No |Month-to-month |Yes |Electronic check |70.70 |151.65 |Yes
|===

5 rows × 21 columns
----

== Exploratory Data Analysis


+*In[503]:*+
[source, ipython3]
----
import matplotlib.pyplot as plt
import seaborn as sns
import math
----


+*In[755]:*+
[source, ipython3]
----
df.to_csv('~/Desktop/telco_df.csv')
----


+*In[504]:*+
[source, ipython3]
----
ax = sns.countplot(x="Churn", data=df)
ax.set_title('Churn Counts', fontweight='bold')
  
#data
labels=df['Churn'].value_counts().index
values=df['Churn'].value_counts().values

for i, p in enumerate(ax.patches):
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2., height + 0.1, values[i],ha="center", fontweight='bold', 
        size=10)
----


+*Out[504]:*+
----
![png](output_13_0.png)
----


+*In[505]:*+
[source, ipython3]
----
def with_hue(plot, feature, Number_of_categories, hue_categories):
    a = [p.get_height() for p in plot.patches]
    patch = [p for p in plot.patches]
    for i in range(Number_of_categories):
        total = feature.value_counts().values[i]
        for j in range(hue_categories):
            percentage = '{:.1f}%'.format(100 * a[(j*Number_of_categories + i)]/total)
            x = patch[(j*Number_of_categories + i)].get_x() + patch[(j*Number_of_categories + i)].get_width() / 2 - 0.15
            y = patch[(j*Number_of_categories + i)].get_y() + patch[(j*Number_of_categories + i)].get_height()
            ax.annotate(percentage, (x, y), size = 12)
    plt.show()

def without_hue(plot, feature):
    total = len(feature)
    for p in ax.patches:
        percentage = '{:.1f}%'.format(100 * p.get_height()/total)
        x = p.get_x() + p.get_width() / 2 - 0.05
        y = p.get_y() + p.get_height()
        ax.annotate(percentage, (x, y), size = 12)
    plt.show()
----

== Demographic Data


+*In[506]:*+
[source, ipython3]
----
plt.figure(figsize = (7,5))
ax = sns.countplot('gender', hue = 'Churn', data=df.loc[df['Churn']!="No"], palette="autumn_r")
ax.set_title('Churn % by Gender', fontweight='bold')
plt.xticks(size = 12)
plt.xlabel('gender', size = 12)
plt.yticks(size = 12)
plt.ylabel('Accounts', size = 12)

with_hue(ax, df.gender,1,2)
----


+*Out[506]:*+
----
![png](output_16_0.png)
----


+*In[507]:*+
[source, ipython3]
----
plt.figure(figsize = (7,5))
ax = sns.countplot('SeniorCitizen', hue = 'Churn', data=df, palette="Greys" )
ax.set_title('Churn % by Seniors', fontweight='bold')
plt.xticks(size = 12)
plt.xlabel('SeniorCitizen', size = 12)
plt.yticks(size = 12)
plt.ylabel('Accounts', size = 12)

with_hue(ax, df.SeniorCitizen,2,2)
----


+*Out[507]:*+
----
![png](output_17_0.png)
----

== Subscription Data


+*In[508]:*+
[source, ipython3]
----
plt.figure(figsize=(8,5))
total = float(len(df))
ax = sns.countplot(x="Contract", hue="Churn", data=df, palette="summer_r")
ax.set_title('Churn % by Contract', fontweight='bold')
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width() / 2 - 0.05
    y = p.get_y() + p.get_height()
    ax.annotate(percentage, (x, y),ha='center')
plt.show()
----


+*Out[508]:*+
----
![png](output_19_0.png)
----


+*In[509]:*+
[source, ipython3]
----
plt.figure(figsize = (7,5))
ax = sns.countplot('Contract', hue = 'Churn', data=df.loc[df['Churn']!="No"], palette="summer_r")
ax.set_title('Churn % by Contract', fontweight='bold')
plt.xticks(size = 12)
plt.xlabel('Contract', size = 12)
plt.yticks(size = 12)
plt.ylabel('Accounts', size = 12)

with_hue(ax, df.Contract,1,3)
----


+*Out[509]:*+
----
![png](output_20_0.png)
----


+*In[510]:*+
[source, ipython3]
----
plt.figure(figsize=(8,5))
total = float(len(df))
ax = sns.countplot(x="InternetService", hue="Churn", data=df, palette="winter_r")
ax.set_title('Churn % by Internet Service', fontweight='bold')
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width() / 2 - 0.05
    y = p.get_y() + p.get_height()
    ax.annotate(percentage, (x, y),ha='center')
plt.show()
----


+*Out[510]:*+
----
![png](output_21_0.png)
----


+*In[511]:*+
[source, ipython3]
----
plt.figure(figsize = (7,5))
ax = sns.countplot('InternetService', hue = 'Churn', data=df.loc[df['Churn']!="No"], palette="ocean")
ax.set_title('Churn % by Internet Service', fontweight='bold')
plt.xticks(size = 12)
plt.xlabel('InternetService', size = 12)
plt.yticks(size = 12)
plt.ylabel('Accounts', size = 12)

with_hue(ax, df.InternetService,1,3)
----


+*Out[511]:*+
----
![png](output_22_0.png)
----


+*In[512]:*+
[source, ipython3]
----
plt.figure(figsize=(11,5))
total = float(len(df))
ax = sns.countplot(x="PaymentMethod", hue="Churn", data=df, palette="spring_r")
ax.set_title('Churn % by Payment Method', fontweight='bold')
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width() / 2 - 0.05
    y = p.get_y() + p.get_height()
    ax.annotate(percentage, (x, y),ha='center')
plt.show()
----


+*Out[512]:*+
----
![png](output_23_0.png)
----


+*In[513]:*+
[source, ipython3]
----
plt.figure(figsize = (11,5))
ax = sns.countplot('PaymentMethod', hue = 'Churn', data=df.loc[df['Churn']!="No"], palette="spring_r")
ax.set_title('Churn % by Payment Method', fontweight='bold')
plt.xticks(size = 12)
plt.xlabel('PaymentMethod', size = 12)
plt.yticks(size = 12)
plt.ylabel('Accounts', size = 12)

with_hue(ax, df.PaymentMethod,1,4)
----


+*Out[513]:*+
----
![png](output_24_0.png)
----


+*In[532]:*+
[source, ipython3]
----
plt.figure(figsize=(8,5))
total = float(len(df))
ax = sns.countplot(x="PaperlessBilling", hue="Churn", data=df, palette="plasma_r")
ax.set_title('Churn % by Paperless Billing', fontweight='bold')
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width() / 2 - 0.05
    y = p.get_y() + p.get_height()
    ax.annotate(percentage, (x, y),ha='center')
plt.show()
----


+*Out[532]:*+
----
![png](output_25_0.png)
----


+*In[540]:*+
[source, ipython3]
----
g = sns.FacetGrid(df, col="PaperlessBilling", height=4, aspect=.9)
ax = g.map(sns.barplot, "Contract", "Churn2", palette = "Blues_d", order= ['Month-to-month', 'One year', 'Two year'])
----


+*Out[540]:*+
----
![png](output_26_0.png)
----


+*In[529]:*+
[source, ipython3]
----
plt.figure(figsize=(8,5))
total = float(len(df))
ax = sns.countplot(x="DeviceProtection", hue="Churn", data=df, palette="coolwarm")
ax.set_title('Churn % by Device Protection', fontweight='bold')
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width() / 2 - 0.05
    y = p.get_y() + p.get_height()
    ax.annotate(percentage, (x, y),ha='center')
plt.show()
----


+*Out[529]:*+
----
![png](output_27_0.png)
----


+*In[543]:*+
[source, ipython3]
----
cols = ["OnlineSecurity", "OnlineBackup", "DeviceProtection", "TechSupport", "StreamingTV", "StreamingMovies"]
df1 = pd.melt(df[df["InternetService"] != "No"][cols]).rename({'value': 'Has service'}, axis=1)
plt.figure(figsize=(10, 4.5))
ax = sns.countplot(data=df1, x='variable', hue='Has service')
ax.set(xlabel='Additional service', ylabel='Num of customers')
ax.set_title('# of Customers with Additional Services', fontweight='bold')
plt.show()
----


+*Out[543]:*+
----
![png](output_28_0.png)
----


+*In[544]:*+
[source, ipython3]
----
plt.figure(figsize=(10, 4.5))
df1 = df[(df.InternetService != "No") & (df.Churn == "Yes")]
df1 = pd.melt(df1[cols]).rename({'value': 'Has service'}, axis=1)
ax = sns.countplot(data=df1, x='variable', hue='Has service', hue_order=['No', 'Yes'])
ax.set(xlabel='Additional service', ylabel='Num of churns')
ax.set_title('Account Churn & Additional Services', fontweight='bold')
plt.show()
----


+*Out[544]:*+
----
![png](output_29_0.png)
----


+*In[514]:*+
[source, ipython3]
----
#Converting Churn to mean for plotting
#Adding new Churn column as binary
def label_churn (row):
   if row['Churn'] == 'Yes' :
      return 1
   if row['Churn'] == 'No' :
        return 0
   return 'Other'

df.apply (lambda row: label_churn(row), axis=1)
----


+*Out[514]:*+
----0       0
1       0
2       1
3       0
4       1
       ..
7038    0
7039    0
7040    0
7041    1
7042    0
Length: 7043, dtype: int64----


+*In[515]:*+
[source, ipython3]
----
df['Churn2'] = df.apply (lambda row: label_churn(row), axis=1)
df.head(2)
----


+*Out[515]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |customerID |gender |SeniorCitizen |Partner |Dependents |tenure
|PhoneService |MultipleLines |InternetService |OnlineSecurity |...
|TechSupport |StreamingTV |StreamingMovies |Contract |PaperlessBilling
|PaymentMethod |MonthlyCharges |TotalCharges |Churn |Churn2
|0 |7590-VHVEG |Female |0 |Yes |No |1 |No |No phone service |DSL |No
|... |No |No |No |Month-to-month |Yes |Electronic check |29.85 |29.85
|No |0

|1 |5575-GNVDE |Male |0 |No |No |34 |Yes |No |DSL |Yes |... |No |No |No
|One year |No |Mailed check |56.95 |1889.50 |No |0
|===

2 rows × 22 columns
----


+*In[525]:*+
[source, ipython3]
----
plt.figure(figsize = (11,5))
ax = sns.scatterplot(x = "tenure", y = "Churn2", data = df.groupby('tenure').Churn2.mean().reset_index())
ax.set_title('Churn & Tenure', fontweight='bold')
plt.xticks(size = 12)
plt.xlabel('Tenure', size = 12)
plt.yticks(size = 12)
plt.ylabel('Avg. Churn', size = 12)

----


+*Out[525]:*+
----Text(0, 0.5, 'Avg. Churn')
![png](output_32_1.png)
----


+*In[527]:*+
[source, ipython3]
----
#Matrix can only represent numerical valued fields
corrMatrix = df.corr()
sns.heatmap(corrMatrix, annot=True)
plt.show()
----


+*Out[527]:*+
----
![png](output_33_0.png)
----

== Clustering Charges/Tensure for Categorical Correlation

== Adding low, mid, high categories for MonthlyCharges, TotalCharges, Tenure columns to help predictions

== Total Charges Cluster


+*In[551]:*+
[source, ipython3]
----
from sklearn.cluster import KMeans
#elbow graph 
#creating inertia graph 
sse = {}

#creating recency pandas series 
tx_total = df[['TotalCharges']]
for k in range(1,15):
    kmeans = KMeans(n_clusters = k, max_iter= 1_000).fit(tx_total)
    tx_total['clusters'] = kmeans.labels_
    sse[k] = kmeans.inertia_
    
plt.figure()
plt.plot(list(sse.keys()), list(sse.values()))
plt.xlabel('Number of Clusters')
plt.show()

#WE'RE GOING TO PROCEED WITH 3 CLUSTERS
----


+*Out[551]:*+
----
![png](output_37_0.png)
----


+*In[557]:*+
[source, ipython3]
----
import chart_studio.plotly.plotly as py
import plotly.offline as pyoff
import plotly.graph_objs as go

#starting with totalcharges
kmeans = KMeans(n_clusters = 3)
kmeans.fit(df[['TotalCharges']])

#add cluster column to df
df['TotalChargesCluster'] = kmeans.predict(df[['TotalCharges']])
----


+*In[560]:*+
[source, ipython3]
----
#creating the funtuon now since we're going to use it many times
#from previous notebooks
def order_cluster(cluster_field_name, target_field_name,df,ascending):
    new_cluster_field_name = 'new_' + cluster_field_name
    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()
    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)
    df_new['index'] = df_new.index
    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)
    df_final = df_final.drop([cluster_field_name],axis=1)
    df_final = df_final.rename(columns={"index":cluster_field_name})
    return df_final

df= order_cluster('TotalChargesCluster', 'TotalCharges', df, True)
----


+*In[561]:*+
[source, ipython3]
----
df['TotalChargesCluster'] = df['TotalChargesCluster'].map({0: 'Low', 
                                                          1: 'Mid',
                                                          2: 'High'})
----


+*In[563]:*+
[source, ipython3]
----
#plotting total charges clusters on churn rate 
#plot_churn(df, 'TotalChargesCluster', 'Total Charges Cluster Based on Churn')
----


+*In[564]:*+
[source, ipython3]
----
df.groupby('TotalChargesCluster')['TotalCharges'].describe()
----


+*Out[564]:*+
----
count

mean

std

min

25%

50%

75%

max

TotalChargesCluster

High

1245.0

6309.779197

996.325466

4811.6

5497.050

6157.600

7049.7500

8684.8

Low

4190.0

690.316778

577.758498

0.0

160.925

538.350

1148.0375

2001.5

Mid

1608.0

3301.036256

815.431754

2003.6

2570.150

3243.925

4003.2125

4808.7
----

== Monthly Charges Cluster


+*In[565]:*+
[source, ipython3]
----
#Grouping the totalcharges
kmeans = KMeans(n_clusters = 3)
kmeans.fit(df[['MonthlyCharges']])

#add cluster column to df
df['MonthlyChargesCluster'] = kmeans.predict(df[['MonthlyCharges']])

df= order_cluster('MonthlyChargesCluster', 'MonthlyCharges', df, True)

df['MonthlyChargesCluster'] = df['MonthlyChargesCluster'].map({0: 'Low', 
                                                              1: 'Mid',
                                                              2: 'High'})
#plotting total charges clusters on churn rate 
#plot_churn(df, 'MonthlyChargesCluster', 'Monthly Charges Cluster Based on Churn')
----

== Tenure Cluster


+*In[567]:*+
[source, ipython3]
----
#Grouping the tenure
kmeans = KMeans(n_clusters = 3)
kmeans.fit(df[['tenure']])

#add cluster column to df
df['TenureCluster'] = kmeans.predict(df[['tenure']])

df= order_cluster('TenureCluster', 'tenure', df, True)

df['TenureCluster'] = df['TenureCluster'].map({0: 'Low', 
                                                1: 'Mid',
                                                2: 'High'})

#plotting total charges clusters on churn rate 
#plot_churn(df, 'TenureCluster', 'Tenure Cluster Based on Churn')
----


+*In[568]:*+
[source, ipython3]
----
df.head()
#sanity check
----


+*Out[568]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |customerID |gender |SeniorCitizen |Partner |Dependents |tenure
|PhoneService |MultipleLines |InternetService |OnlineSecurity |...
|Contract |PaperlessBilling |PaymentMethod |MonthlyCharges |TotalCharges
|Churn |Churn2 |TotalChargesCluster |MonthlyChargesCluster
|TenureCluster
|0 |7590-VHVEG |Female |0 |Yes |No |1 |No |No phone service |DSL |No
|... |Month-to-month |Yes |Electronic check |29.85 |29.85 |No |0 |Low
|Low |Low

|1 |6713-OKOMC |Female |0 |No |No |10 |No |No phone service |DSL |Yes
|... |Month-to-month |No |Mailed check |29.75 |301.90 |No |0 |Low |Low
|Low

|2 |7469-LKBCI |Male |0 |No |No |16 |Yes |No |No |No internet service
|... |Two year |No |Credit card (automatic) |18.95 |326.80 |No |0 |Low
|Low |Low

|3 |8779-QRDMV |Male |1 |No |No |1 |No |No phone service |DSL |No |...
|Month-to-month |Yes |Electronic check |39.65 |39.65 |Yes |1 |Low |Low
|Low

|4 |1680-VDCWW |Male |0 |Yes |No |12 |Yes |No |No |No internet service
|... |One year |No |Bank transfer (automatic) |19.80 |202.25 |No |0 |Low
|Low |Low
|===

5 rows × 25 columns
----

== Copy DF for Categorical Correlation


+*In[597]:*+
[source, ipython3]
----
pd.options.mode.chained_assignment = None  # default='warn'

df2 = df.copy()
df2.head()
----


+*Out[597]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |customerID |gender |SeniorCitizen |Partner |Dependents |tenure
|PhoneService |MultipleLines |InternetService |OnlineSecurity |...
|Contract |PaperlessBilling |PaymentMethod |MonthlyCharges |TotalCharges
|Churn |Churn2 |TotalChargesCluster |MonthlyChargesCluster
|TenureCluster
|0 |7590-VHVEG |Female |0 |Yes |No |1 |No |No phone service |DSL |No
|... |Month-to-month |Yes |Electronic check |29.85 |29.85 |No |0 |Low
|Low |Low

|1 |6713-OKOMC |Female |0 |No |No |10 |No |No phone service |DSL |Yes
|... |Month-to-month |No |Mailed check |29.75 |301.90 |No |0 |Low |Low
|Low

|2 |7469-LKBCI |Male |0 |No |No |16 |Yes |No |No |No internet service
|... |Two year |No |Credit card (automatic) |18.95 |326.80 |No |0 |Low
|Low |Low

|3 |8779-QRDMV |Male |1 |No |No |1 |No |No phone service |DSL |No |...
|Month-to-month |Yes |Electronic check |39.65 |39.65 |Yes |1 |Low |Low
|Low

|4 |1680-VDCWW |Male |0 |Yes |No |12 |Yes |No |No |No internet service
|... |One year |No |Bank transfer (automatic) |19.80 |202.25 |No |0 |Low
|Low |Low
|===

5 rows × 25 columns
----


+*In[598]:*+
[source, ipython3]
----
#Categorical variables to numeric features
#import Label Encoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
dummy_columns = [] #array for multiple value columns

for column in df2.columns:
    if df2[column].dtype == object and column != 'customerID':
        if df2[column].nunique() == 2:
            #apply Label Encoder for binary ones
            df2[column] = le.fit_transform(df2[column]) 
        else:
            dummy_columns.append(column)
#apply get dummies for selected columns
df2 = pd.get_dummies(data = df2,columns = dummy_columns)
----


+*In[599]:*+
[source, ipython3]
----
df2.head()
----


+*Out[599]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |customerID |gender |SeniorCitizen |Partner |Dependents |tenure
|PhoneService |PaperlessBilling |MonthlyCharges |TotalCharges |...
|PaymentMethod_Mailed check |TotalChargesCluster_High
|TotalChargesCluster_Low |TotalChargesCluster_Mid
|MonthlyChargesCluster_High |MonthlyChargesCluster_Low
|MonthlyChargesCluster_Mid |TenureCluster_High |TenureCluster_Low
|TenureCluster_Mid
|0 |7590-VHVEG |0 |0 |1 |0 |1 |0 |1 |29.85 |29.85 |... |0 |0 |1 |0 |0 |1
|0 |0 |1 |0

|1 |6713-OKOMC |0 |0 |0 |0 |10 |0 |0 |29.75 |301.90 |... |1 |0 |1 |0 |0
|1 |0 |0 |1 |0

|2 |7469-LKBCI |1 |0 |0 |0 |16 |1 |0 |18.95 |326.80 |... |0 |0 |1 |0 |0
|1 |0 |0 |1 |0

|3 |8779-QRDMV |1 |1 |0 |0 |1 |0 |1 |39.65 |39.65 |... |0 |0 |1 |0 |0 |1
|0 |0 |1 |0

|4 |1680-VDCWW |1 |0 |1 |0 |12 |1 |0 |19.80 |202.25 |... |0 |0 |1 |0 |0
|1 |0 |0 |1 |0
|===

5 rows × 52 columns
----

== Logistic Regression


+*In[574]:*+
[source, ipython3]
----
corr_matrix = df2.corr()
corr_matrix['Churn2'].sort_values(ascending = False)
----


+*Out[574]:*+
----Churn                                      1.000000
Churn2                                     1.000000
Contract_Month-to-month                    0.405103
OnlineSecurity_No                          0.342637
TechSupport_No                             0.337281
TenureCluster_Low                          0.318752
InternetService_Fiber optic                0.308020
PaymentMethod_Electronic check             0.301919
OnlineBackup_No                            0.268005
DeviceProtection_No                        0.252481
MonthlyCharges                             0.193356
PaperlessBilling                           0.191825
MonthlyChargesCluster_High                 0.151947
SeniorCitizen                              0.150889
TotalChargesCluster_Low                    0.149420
StreamingMovies_No                         0.130845
StreamingTV_No                             0.128916
StreamingTV_Yes                            0.063228
StreamingMovies_Yes                        0.061382
MultipleLines_Yes                          0.040102
MonthlyChargesCluster_Mid                  0.027884
PhoneService                               0.011942
gender                                    -0.008612
MultipleLines_No phone service            -0.011942
MultipleLines_No                          -0.032569
TotalChargesCluster_Mid                   -0.054176
DeviceProtection_Yes                      -0.066160
TenureCluster_Mid                         -0.076547
OnlineBackup_Yes                          -0.082255
PaymentMethod_Mailed check                -0.091683
PaymentMethod_Bank transfer (automatic)   -0.117937
InternetService_DSL                       -0.124214
TotalChargesCluster_High                  -0.132672
PaymentMethod_Credit card (automatic)     -0.134302
Partner                                   -0.150448
Dependents                                -0.164221
TechSupport_Yes                           -0.164674
OnlineSecurity_Yes                        -0.171226
Contract_One year                         -0.177820
MonthlyChargesCluster_Low                 -0.198118
TotalCharges                              -0.198324
DeviceProtection_No internet service      -0.227890
StreamingMovies_No internet service       -0.227890
StreamingTV_No internet service           -0.227890
InternetService_No                        -0.227890
OnlineSecurity_No internet service        -0.227890
TechSupport_No internet service           -0.227890
OnlineBackup_No internet service          -0.227890
TenureCluster_High                        -0.263222
Contract_Two year                         -0.302253
tenure                                    -0.352229
Name: Churn2, dtype: float64----


+*In[681]:*+
[source, ipython3]
----
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.feature_selection import VarianceThreshold
from yellowbrick.datasets import load_occupancy
from yellowbrick.model_selection import FeatureImportances
----


+*In[588]:*+
[source, ipython3]
----
X = df2.drop(['customerID', 'Churn', 'Churn2'], axis = 1)
y = df2[['Churn2']]

X_train, X_test, y_train, y_test = train_test_split(
     X, y, test_size=0.33, random_state=42)
----


+*In[582]:*+
[source, ipython3]
----
#whats our baseline?
df['Churn2'].value_counts(normalize = True)
----


+*Out[582]:*+
----0    0.73463
1    0.26537
Name: Churn2, dtype: float64----

== Logistic Regression


+*In[757]:*+
[source, ipython3]
----
lr = LogisticRegression(penalty='none', random_state = 0, tol = 10**-10, 
                        max_iter=50000, solver='lbfgs', class_weight={0:.4, 1:.9})
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)

print('LR Classification report: \n', classification_report(y_test, lr_pred ))
#print('Logistic Regreen Confusion matrix: \n', confusion_matrix(y_test, lr_pred ))

cf_matrix = confusion_matrix(y_test, lr_pred)
plt.figure(figsize=(3, 3))
sns.heatmap(cf_matrix, annot=True, 
            fmt='2', cmap='Blues');

#class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None

----


+*Out[757]:*+
----
LR Classification report: 
               precision    recall  f1-score   support

           0       0.91      0.77      0.83      1714
           1       0.54      0.77      0.64       611

    accuracy                           0.77      2325
   macro avg       0.72      0.77      0.73      2325
weighted avg       0.81      0.77      0.78      2325


![png](output_58_1.png)
----


+*In[730]:*+
[source, ipython3]
----
viz = FeatureImportances(lr)
viz.fit(X, y)
viz.show();
----


+*Out[730]:*+
----
![png](output_59_0.png)
----

== Random Forest Classifier


+*In[759]:*+
[source, ipython3]
----
rf = RandomForestClassifier(n_estimators = 30, max_depth=2)
rf.fit(X_train,y_train)
RandomForestClassifier(bootstrap=True, class_weight={0:.4, 1:.9}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
rf_pred = rf.predict(X_test)
rf.score(X_test, y_test)


print('RF Classification report: \n', classification_report(y_test, rf_pred ))
#print('Confusion matrix: \n', confusion_matrix(y_test, rf_pred ))

cf_matrix = confusion_matrix(y_test, rf_pred)
plt.figure(figsize=(3, 3))
sns.heatmap(cf_matrix, annot=True, 
            fmt='2', cmap='Blues');
----


+*Out[759]:*+
----
RF Classification report: 
               precision    recall  f1-score   support

           0       0.78      0.97      0.87      1714
           1       0.73      0.25      0.37       611

    accuracy                           0.78      2325
   macro avg       0.76      0.61      0.62      2325
weighted avg       0.77      0.78      0.74      2325


![png](output_61_1.png)
----


+*In[761]:*+
[source, ipython3]
----
viz = FeatureImportances(rf)
viz.fit(X, y)
viz.show();
----


+*Out[761]:*+
----
![png](output_62_0.png)
----

== Random Forest with Feature Selection: RFE

=== Feature ranking with recursive feature elimination only.


+*In[758]:*+
[source, ipython3]
----
from sklearn.feature_selection import RFE
# Create the RFE object and rank each pixel

rf_2 = RandomForestClassifier()      
rfe = RFE(estimator=rf_2, n_features_to_select=10, step=1)
rfe = rfe.fit(X_train, y_train)
rfe_pred = rfe.predict(X_test)
rfe.score(X_test, y_test)

print('RFE Classification report: \n', classification_report(y_test, rfe_pred ))
#print('Confusion matrix: \n', confusion_matrix(y_test, rfe_pred ))

cf_matrix = confusion_matrix(y_test, rfe_pred)
plt.figure(figsize=(3, 3))
sns.heatmap(cf_matrix, annot=True, 
            fmt='2', cmap='Blues');
----


+*Out[758]:*+
----
RFE Classification report: 
               precision    recall  f1-score   support

           0       0.82      0.89      0.85      1714
           1       0.60      0.47      0.52       611

    accuracy                           0.78      2325
   macro avg       0.71      0.68      0.69      2325
weighted avg       0.76      0.78      0.77      2325


![png](output_64_1.png)
----


+*In[728]:*+
[source, ipython3]
----
viz = FeatureImportances(rf_2)
viz.fit(X, y)
viz.show();
----


+*Out[728]:*+
----
![png](output_65_0.png)
----

== Predicting the Churn Probability of Users


+*In[732]:*+
[source, ipython3]
----
#predicting on entire dataset
cols = X_train.columns
df['proba'] = lr.predict_proba(df2[cols])[:,1]

#[:,1] denotes the predicitive probabioity of being in the positive class
----


+*In[733]:*+
[source, ipython3]
----
df[['customerID', 'proba']].isnull().sum().sum()
#sanity check
----


+*Out[733]:*+
----0----


+*In[734]:*+
[source, ipython3]
----
df[['customerID', 'proba']].head()
----


+*Out[734]:*+
----
[cols=",,",options="header",]
|===
| |customerID |proba
|0 |7590-VHVEG |0.620966
|1 |6713-OKOMC |0.289035
|2 |7469-LKBCI |0.028413
|3 |8779-QRDMV |0.729509
|4 |1680-VDCWW |0.070464
|===
----


+*In[ ]:*+
[source, ipython3]
----
df_proba = df[['customerID', 'proba']]
df_proba.to_csv('./datasets/telco_churn_proba.csv')
----
